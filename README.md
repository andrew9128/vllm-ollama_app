# vllm-ollama_app

[![Python 3.9+](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.23.1-FF4B4B.svg)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Интеллектуальный чат-интерфейс с поддержкой различных языковых моделей (LLM) и интеграцией с VLLM/Ollama серверами.

![Скриншот интерфейса](https://via.placeholder.com/800x400.png?text=Chat+Interface+Preview)

## ✨ Особенности

- Поддержка нескольких LLM моделей (Qwen, Llama, и др.)
- Интеграция с VLLM и Ollama серверами
- История чатов с сохранением в MySQL
- Поиск по истории сообщений
- Настройка параметров генерации

### Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/ваш-username/ваш-репозиторий.git
cd ваш-репозиторий
